{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Previsão do Percentual de Cumprimento de Metas\n",
    "\n",
    "### Tarefa \n",
    "\n",
    "Crie um modelo capaz de prever o **percentual de cumprimento da meta** ao fim do ano para um determinado funcionário. Descreva cada detalhe considerado para o modelo, como qual foia estratégia de separação entre teste e validação e métricas de performance.\n",
    "\n",
    "### Considerações\n",
    "\n",
    "Todo processo de resolução de problemas de data-science envolvem questões não muito claras e dados longe de serem totalmente interpretaveis, dessa forma para resolver a tarefa proposta é necessário esclarecer alguns pontos dela usando algumas considerações que surgiram neste projeto.\n",
    "\n",
    "\n",
    "##### Sobre os dados...\n",
    "\n",
    "**meta**: em geral os funcionários tem 5 KPIs que são alocados a ele, mas isso não significa que eles são todos usados, talvez seja padrão do software de gestão utilizado ter esses KPIs para o cargo/area do funcionário e dentro do escopo do trabalho dele, os seus gestores dão um 'flag' nos KPIs que serão utilizados para compor os resultados deles, esse 'flag' na base de dados disponibilizada é dada pela coluna 'Status Meta' quando aquela linha possui o valor 'Monitoramento Aprovado', dessa forma é possível chegar ao entendimento que uma meta se refere a um KPI que será monitorado para aquele funcionário.\n",
    "\n",
    "**percentual cumprimento da meta ao fim do ano**: cada funcionário pode ter mais de uma meta e de forma geral quando se pensa no percentual de cumprimento de cada meta, não faz muito sentido agregar essas metas concomitantes pois cada KPI apresenta carrega suas caracteristicas próprias, de modo que para ter um modelo que tenha como target o percentual de cumprimento da meta se fará uma previsão para cada uma das metas do funcionário separadamente.\n",
    "\n",
    "**ao fim do ano**: como os dados disponíveis só engloba 10 meses e sendo que boa parte dos funcionários não está presente em todos os meses, foi considerado que faz mais sentido criar um modelo que utilize apenas as informações iniciais do funcionário, no caso apenas suas informações do primeiro mês, e que o percentual de metas cumpridas de cada funcionário no periodo que ele aparece na base é uma boa generalização do resultado dele no ano.\n",
    "\n",
    "##### Sobre o modelo e as métricas...\n",
    "\n",
    "Como o problema busca generalizar uma variável continua que representa uma proporção (das metas), mesmo que essa se mantenha entre 0 e 1 ele é um problema de regressão.\n",
    "\n",
    "**Modelo** Como as features a serem utilizadas são todas categoricas serão testados modelos que lidam bem com esse tipo de distribuição discreta.\n",
    "\n",
    "**Metricas** Sendo um problema de regressão, a métrica de Erro Médio Quadrado é uma opção adequada pois tratará de tentar manter os valores o mais próximo dos reais sendo que não temos um target com outliers ou distribuição de calda longa, o que seria um caso para utilizar alguma outra métrica. \n",
    "\n",
    "**Validação** Uma média das validações cruzadas em 5 folds do dataset.\n",
    "\n",
    "### Premissas\n",
    "\n",
    "Como na base de dados bruta fornecida tem inconsistências e também não é muito claro a definição de meta comprida se faz necessário criar algumas premissas sobre a lógica do negócio e criar o pipelino do modelo a partir delas.\n",
    "\n",
    "\n",
    "    1. Uma meta é um KPI com Monitoramento Aprovado.\n",
    "    2. Metas são referentes a apenas aquele mês.\n",
    "    3. O percentual de cumprimento de uma meta para um mês é representado pela coluna Atingido Mês (ating_mes).\n",
    "    4. O percentual de cumprimento da meta (target) um funcionário em certo periodo é calculado como:\n",
    "         target = (soma_metas / quantidade_de_metas) / 100\n",
    "         sendo que:\n",
    "             quantidade_de_metas é o total de metas do período\n",
    "             soma_metas é a soma do valor dessas metas\n",
    "             \n",
    "             \n",
    "### Conclusões\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1. Preparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Bibliotecas de validação\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Bibliotecas de modelos\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Ignorar warnings do sklearn\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base com 7858 linhas e 33 colunas.\n"
     ]
    }
   ],
   "source": [
    "# Lendo base\n",
    "df = pd.read_pickle('../data/processed/ambev-final-dataset.pkl')\n",
    "print('Base com {} linhas e {} colunas.'.format(*df.shape))\n",
    "y = df.target\n",
    "X = df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Seleção do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23674694441387314"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline modelo média do target\n",
    "y_pred = pd.Series([y.mean() for v in y])\n",
    "# RMSE do modelo média\n",
    "((y - y_pred) ** 2).mean() ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos a serem testados\n",
    "models = [\n",
    "    ('LGBM', LGBMRegressor()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('RF', RandomForestRegressor()),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM\tRMSE: 0.12914\t\n",
      "KNN\tRMSE: 0.15039\t\n",
      "RF\tRMSE: 0.13395\t\n"
     ]
    }
   ],
   "source": [
    "# Computa as validações cruzadas de todos os modelos inputados\n",
    "folds = 5\n",
    "\n",
    "for name, model in models:\n",
    "    # calcula as cvs\n",
    "    cv_results = cross_val_score(model, X, y, cv=folds, scoring='neg_mean_squared_error')\n",
    "\n",
    "    # salva/printa os resultados\n",
    "    print('{}\\tRMSE: {:.5f}\\t'.format(name, (-1 * cv_results.mean()) ** 0.5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modelo escolhido\n",
    "model = LGBMRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tuning de Parametros e CV Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "          fit_params=None, iid='warn', n_iter=30, n_jobs=None,\n",
       "          param_distributions={'learning_rate': [0.1, 0.05, 0.01], 'max_depth': [-1, -2, -4], 'min_child_samples': [20, 30, 50, 70], 'min_child_weight': [0.001, 0.01, 0.05], 'min_split_gain': [0.0, 0.01, 0.1], 'n_estimators': [50, 100, 150, 200], 'num_leaves': [20, 31, 40, 60], 'random_state': [100], 'subsample': [1.0, 0.9, 0.8]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Função para reportar os modelos com melhores parametros\n",
    "def report(results, top=3):\n",
    "    for i in range(1, top + 1):\n",
    "        models = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for model in models:\n",
    "            print(\"Modelo: {0}\".format(i))\n",
    "            print(\"RMSE: {0:.3f} (-mse: {1:.3f}) (std: {1:.3f})\".format(\n",
    "                  (-1 * results['mean_test_score'][model]) ** 0.5,\n",
    "                  results['mean_test_score'][model],\n",
    "                  results['std_test_score'][model]))\n",
    "            print(\"Parametros: {0}\\n\".format(results['params'][model]))\n",
    "\n",
    "\n",
    "# Parametros a serem explorados\n",
    "param_dist = {\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'max_depth': [-1, -2, -4],\n",
    "    'min_child_samples': [20, 30, 50, 70],\n",
    "    'min_child_weight': [0.001, 0.01, 0.05],\n",
    "    'min_split_gain': [0.0, 0.01, 0.1],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'num_leaves': [20, 31, 40, 60],\n",
    "    'random_state': [100],\n",
    "    'subsample': [1.0, 0.9, 0.8]}\n",
    "\n",
    "# Tuning de parametros com busca aleatória e validação cruzada\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                   n_iter=30, cv=5, scoring='neg_mean_squared_error')\n",
    "# Rodando a busca\n",
    "random_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: 1\n",
      "RMSE: 0.129 (-mse: -0.017) (std: -0.017)\n",
      "Parametros: {'subsample': 0.8, 'random_state': 100, 'num_leaves': 31, 'n_estimators': 200, 'min_split_gain': 0.0, 'min_child_weight': 0.01, 'min_child_samples': 50, 'max_depth': -1, 'learning_rate': 0.1}\n",
      "\n",
      "Modelo: 2\n",
      "RMSE: 0.129 (-mse: -0.017) (std: -0.017)\n",
      "Parametros: {'subsample': 0.9, 'random_state': 100, 'num_leaves': 60, 'n_estimators': 200, 'min_split_gain': 0.0, 'min_child_weight': 0.001, 'min_child_samples': 50, 'max_depth': -1, 'learning_rate': 0.05}\n",
      "\n",
      "Modelo: 3\n",
      "RMSE: 0.129 (-mse: -0.017) (std: -0.017)\n",
      "Parametros: {'subsample': 1.0, 'random_state': 100, 'num_leaves': 60, 'n_estimators': 200, 'min_split_gain': 0.0, 'min_child_weight': 0.01, 'min_child_samples': 50, 'max_depth': -4, 'learning_rate': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo com os parametros tunados\n",
    "model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('boosting_type', 'gbdt')\n",
      "('class_weight', None)\n",
      "('colsample_bytree', 1.0)\n",
      "('importance_type', 'split')\n",
      "('learning_rate', 0.1)\n",
      "('max_depth', -1)\n",
      "('min_child_samples', 50)\n",
      "('min_child_weight', 0.01)\n",
      "('min_split_gain', 0.0)\n",
      "('n_estimators', 200)\n",
      "('n_jobs', -1)\n",
      "('num_leaves', 31)\n",
      "('objective', None)\n",
      "('random_state', 100)\n",
      "('reg_alpha', 0.0)\n",
      "('reg_lambda', 0.0)\n",
      "('silent', True)\n",
      "('subsample', 0.8)\n",
      "('subsample_for_bin', 200000)\n",
      "('subsample_freq', 0)\n"
     ]
    }
   ],
   "source": [
    "# Parametros escolhidos\n",
    "print(*model.get_params().items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Importância das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model = model.fit(X, y)\n",
    "importances = model.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(1, figsize=(14, 13))\n",
    "plt.title(\"Importância das Features\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"g\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices],rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mes                        10\n",
       "pais                        8\n",
       "mundo                      30\n",
       "area_regional              23\n",
       "unidade                   325\n",
       "grupo_cargo               121\n",
       "cargo                     295\n",
       "grade                      17\n",
       "banda                      14\n",
       "area                       99\n",
       "id_kpi                    720\n",
       "diretoria                  15\n",
       "area_diretoria              9\n",
       "funcao                     92\n",
       "tipo_meta                   9\n",
       "categoria_kpi              68\n",
       "nome_kpi                 1149\n",
       "peso_kpi                    9\n",
       "prazo                      10\n",
       "regra_alcance_parcial     468\n",
       "meta_projeto                3\n",
       "status_meta                 2\n",
       "abrev_cargo                25\n",
       "abrev_grupo_cargo          20\n",
       "nivel_cargo                 5\n",
       "regra_n1                   37\n",
       "regra_n2                   36\n",
       "regra_n3                   30\n",
       "regra_n4                   28\n",
       "regra_real                  2\n",
       "regra_lacuna                2\n",
       "regra_pontosl               2\n",
       "target                   1186\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ambev_data_challenge]",
   "language": "python",
   "name": "conda-env-ambev_data_challenge-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
